{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 2: How to create a fMRI analysis workflow\n",
    "\n",
    "The purpose of this section is that you setup a fMRI analysis workflow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st-level Analysis Workflow Structure\n",
    "\n",
    "In this notebook we will create a workflow that performs 1st-level analysis and normalizes the resulting beta weights to the MNI template. In concrete steps this means:\n",
    "\n",
    "    1. Specify 1st-level model parameters\n",
    "    2. Specify 1st-level contrasts\n",
    "    3. Estimate 1st-level contrasts\n",
    "    4. Normalize 1st-level contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "It's always best to have all relevant module imports at the beginning of your script. So let's import what we most certainly need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the Node and Workflow object\n",
    "from nipype import Node, Workflow\n",
    "\n",
    "# Specify which SPM to use\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('/opt/spm12-dev/spm12_mcr/spm/spm12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nodes and Workflow connections\n",
    "\n",
    "Let's create all the nodes that we need! Make sure to specify all relevant inputs and keep in mind which ones you later on need to connect in your pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify 1st-level model parameters (stimuli onsets, duration, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specify the 1st-level model we need the subject specific onset times and durations of the stimuli. Luckily, as we are working with a BIDS dataset, this information is nicely stored in a `tsv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the workflow here\n",
    "analysis1st = Workflow(name='work_1st', base_dir='/output/')\n",
    "trialinfo = pd.read_table('/data/ds000114/task-fingerfootlips_events.tsv')\n",
    "trialinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nipype.interfaces.base import Bunch\n",
    "for group in trialinfo.groupby('trial_type'):\n",
    "    print(group)\n",
    "    print(\"\")\n",
    "trialinfo = pd.read_table('/data/ds000114/task-fingerfootlips_events.tsv')\n",
    "conditions = []\n",
    "onsets = []\n",
    "durations = []\n",
    "\n",
    "for group in trialinfo.groupby('trial_type'):\n",
    "    conditions.append(group[0])\n",
    "    onsets.append(list(group[1].onset -10)) # subtracting 10s due to removing of 4 dummy scans\n",
    "    durations.append(group[1].duration.tolist())\n",
    "\n",
    "subject_info = [Bunch(conditions=conditions,\n",
    "                      onsets=onsets,\n",
    "                      durations=durations,\n",
    "                      )]\n",
    "\n",
    "from nipype.algorithms.modelgen import SpecifySPMModel\n",
    "\n",
    "# Initiate the SpecifySPMModel node here\n",
    "modelspec = Node(SpecifySPMModel(concatenate_runs=False,\n",
    "                                 input_units='secs',\n",
    "                                 output_units='secs',\n",
    "                                 time_repetition=2.5,\n",
    "                                 high_pass_filter_cutoff=128,\n",
    "                                 subject_info=subject_info),\n",
    "                 name=\"modelspec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This node will also need some additional inputs, such as the preprocessed functional images, the motion parameters etc. We will specify those once we take care of the workflow data input stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify 1st-level contrasts\n",
    "\n",
    "To do any GLM analysis, we need to also define the contrasts that we want to investigate. If we recap, we had three different conditions in the **fingerfootlips** task in this dataset:\n",
    "\n",
    "- **finger**\n",
    "- **foot**\n",
    "- **lips**\n",
    "\n",
    "Therefore, we could create the following contrasts (seven T-contrasts and two F-contrasts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition names\n",
    "condition_names = ['Finger', 'Foot', 'Lips']\n",
    "\n",
    "# Contrasts\n",
    "cont01 = ['average',        'T', condition_names, [1/3., 1/3., 1/3.]]\n",
    "cont02 = ['Finger',         'T', condition_names, [1, 0, 0]]\n",
    "cont03 = ['Foot',           'T', condition_names, [0, 1, 0]]\n",
    "cont04 = ['Lips',           'T', condition_names, [0, 0, 1]]\n",
    "cont05 = ['Finger > others','T', condition_names, [1, -0.5, -0.5]]\n",
    "cont06 = ['Foot > others',  'T', condition_names, [-0.5, 1, -0.5]]\n",
    "cont07 = ['Lips > others',  'T', condition_names, [-0.5, -0.5, 1]]\n",
    "\n",
    "cont08 = ['activation',     'F', [cont02, cont03, cont04]]\n",
    "cont09 = ['differences',    'F', [cont05, cont06, cont07]]\n",
    "\n",
    "contrast_list = [cont01, cont02, cont03, cont04, cont05, cont06, cont07, cont08, cont09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate 1st-level contrasts\n",
    "\n",
    "Before we can estimate the 1st-level contrasts, we first need to create the 1st-level design. Here you can also specify what kind of basis function you want (HRF, FIR, Fourier, etc.), if you want to use time and dispersion derivatives and how you want to model the serial correlation.\n",
    "\n",
    "In this example I propose that you use an HRF basis function, that we model time derivatives and that we model the serial correlation with AR(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import Level1Design\n",
    "# Initiate the Level1Design node here\n",
    "level1design = Node(Level1Design(bases={'hrf': {'derivs': [1, 0]}},\n",
    "                                 timing_units='secs',\n",
    "                                 interscan_interval=2.5,\n",
    "                                 model_serial_correlations='AR(1)'),\n",
    "                    name=\"level1design\")\n",
    "\n",
    "\n",
    "# Now that we have the Model Specification and 1st-Level Design node, we can connect them to each other:\n",
    "# Connect the two nodes here\n",
    "analysis1st.connect([(modelspec, level1design, [('session_info',\n",
    "                                                 'session_info')])])\n",
    "\n",
    "# Now we need to estimate the model. I recommend that you'll use a Classical: 1 method to estimate the model.\n",
    "from nipype.interfaces.spm import EstimateModel\n",
    "# Initiate the EstimateModel node here\n",
    "level1estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# Now we can connect the 1st-Level Design node with the model estimation node.\n",
    "# Connect the two nodes here\n",
    "analysis1st.connect([(level1design, level1estimate, [('spm_mat_file',\n",
    "                                                      'spm_mat_file')])])\n",
    "from nipype.interfaces.spm import EstimateContrast\n",
    "# Initiate the EstimateContrast node here\n",
    "level1conest = Node(EstimateContrast(contrasts=contrast_list),\n",
    "                    name=\"level1conest\")\n",
    "\n",
    "# Now we can connect the model estimation node with the contrast estimation node.\n",
    "analysis1st.connect([(level1estimate, level1conest, [('spm_mat_file',\n",
    "                                                      'spm_mat_file'),\n",
    "                                                     ('beta_images',\n",
    "                                                      'beta_images'),\n",
    "                                                     ('residual_image',\n",
    "                                                      'residual_image')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize 1st-level contrasts\n",
    "\n",
    "Now that the contrasts were estimated in subject space we can put them into a common reference space by normalizing them to a specific template. In this case we will be using SPM12's Normalize routine and normalize to the SPM12 tissue probability map `TPM.nii`.\n",
    "\n",
    "At this step you can also specify the voxel resolution of the output volumes. If you don't specify it, it will normalize to a voxel resolution of 2x2x2mm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import Normalize12\n",
    "\n",
    "# Location of the template\n",
    "template = '/opt/spm12-dev/spm12_mcr/spm/spm12/tpm/TPM.nii'\n",
    "\n",
    "# Initiate the Normalize12 node here\n",
    "normalize = Node(Normalize12(jobtype='estwrite',\n",
    "                             tpm=template,\n",
    "                             write_voxel_sizes=[2, 2, 2]\n",
    "                            ),\n",
    "                 name=\"normalize\")\n",
    "\n",
    "# Connect the nodes here\n",
    "analysis1st.connect([(level1conest, normalize, [('spmT_images',\n",
    "                                                 'apply_to_files')])\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datainput with `SelectFiles` and `iterables` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SelectFiles\n",
    "from nipype import SelectFiles\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': '/data/ds000114/sub-{subj_id}/ses-test/anat/sub-{subj_id}_ses-test_T1w.nii.gz',\n",
    "             'func': '/output/datasink_handson/preproc/sub-{subj_id}_detrend.nii.gz',\n",
    "             'mc_param': '/output/datasink_handson/preproc/sub-{subj_id}.par',\n",
    "             'outliers': '/output/datasink_handson/preproc/art.sub-{subj_id}_outliers.txt'\n",
    "            }\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates, sort_filelist=True),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Now we can specify over which subjects the workflow should iterate. \n",
    "# list of subject identifiers\n",
    "subject_list = ['07']\n",
    "sf.iterables = [('subj_id', subject_list)]\n",
    "\n",
    "\n",
    "# Gunzip Node\n",
    "\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "# Initiate the two Gunzip node here\n",
    "gunzip_anat = Node(Gunzip(), name='gunzip_anat')\n",
    "gunzip_func = Node(Gunzip(), name='gunzip_func')\n",
    "\n",
    "\n",
    "# And as a final step, we just need to connect this SelectFiles node to the rest of the workflow.\n",
    "# Connect SelectFiles node to the other nodes here\n",
    "analysis1st.connect([(sf, gunzip_anat, [('anat', 'in_file')]),\n",
    "                     (sf, gunzip_func, [('func', 'in_file')]),\n",
    "                     (gunzip_anat, normalize, [('out_file', 'image_to_align')]),\n",
    "                     (gunzip_func, modelspec, [('out_file', 'functional_runs')]),\n",
    "                     (sf, modelspec, [('mc_param', 'realignment_parameters'),\n",
    "                                      ('outliers', 'outlier_files'),\n",
    "                                      ])\n",
    "                    ])\n",
    "\n",
    "#Data output with DataSink\n",
    "#Now, before we run the workflow, let's again specify a Datasink folder to only keep those files that we want to keep.\n",
    "from nipype.interfaces.io import DataSink\n",
    "# Initiate DataSink node here\n",
    "# Initiate the datasink node\n",
    "output_folder = 'datasink_handson'\n",
    "datasink = Node(DataSink(base_directory='/output/',\n",
    "                         container=output_folder),\n",
    "                name=\"datasink\")\n",
    "## Use the following substitutions for the DataSink output\n",
    "substitutions = [('_subj_id_', 'sub-')]\n",
    "datasink.inputs.substitutions = substitutions\n",
    "\n",
    "# Connect nodes to datasink here\n",
    "analysis1st.connect([(level1conest, datasink, [('spm_mat_file', '1stLevel.@spm_mat'),\n",
    "                                               ('spmT_images', '1stLevel.@T'),\n",
    "                                               ('spmF_images', '1stLevel.@F'),\n",
    "                                              ]),\n",
    "                     (normalize, datasink, [('normalized_files', 'normalized.@files'),\n",
    "                                            ('normalized_image', 'normalized.@image'),\n",
    "                                           ]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "\n",
    "Now that the workflow is finished, let's visualize it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1st-level analysis output graph\n",
    "analysis1st.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename='/output/work_1st/graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now that everything is ready, we can run the 1st-level analysis workflow. Change ``n_procs`` to the number of jobs/cores you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1st.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's look at the 1st-level Design Matrix of subject one, to verify that everything is as it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Using scipy's loadmat function we can access SPM.mat\n",
    "spmmat = loadmat('/output/datasink_handson/1stLevel/sub-07/SPM.mat',\n",
    "                 struct_as_record=False)\n",
    "designMatrix = spmmat['SPM'][0][0].xX[0][0].X\n",
    "names = [i[0] for i in spmmat['SPM'][0][0].xX[0][0].name[0]]\n",
    "normed_design = designMatrix / np.abs(designMatrix).max(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(normed_design, aspect='auto', cmap='gray', interpolation='none')\n",
    "ax.set_ylabel('Volume id')\n",
    "ax.set_xticks(np.arange(len(names)))\n",
    "ax.set_xticklabels(names, rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look how well the normalization worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "from nilearn.plotting import plot_anat\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "# Load GM probability map of TPM.nii\n",
    "img = nb.load('/opt/spm12-dev/spm12_mcr/spm/spm12/tpm/TPM.nii')\n",
    "GM_template = nb.Nifti1Image(img.get_data()[..., 0], img.affine, img.header)\n",
    "\n",
    "# Plot normalized subject anatomy\n",
    "display = plot_anat('/output/datasink_handson/normalized/sub-07/wsub-07_ses-test_T1w.nii',\n",
    "                    dim=-0.1)\n",
    "\n",
    "# Overlay in edges GM map\n",
    "display.add_edges(GM_template)\n",
    "\n",
    "# Plot raw subject anatomy\n",
    "display = plot_anat('/data/ds000114/sub-07/ses-test/anat/sub-07_ses-test_T1w.nii.gz',\n",
    "                    dim=-0.1)\n",
    "\n",
    "# Overlay in edges GM map\n",
    "display.add_edges(GM_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the contrasts of one subject that we've just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "anatimg = '/data/ds000114/sub-07/ses-test/anat/sub-07_ses-test_T1w.nii.gz'\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0001.nii', title='average',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0002.nii', title='finger',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0003.nii', title='foot',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0004.nii', title='lip',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also check three additional contrasts Finger > others, Foot > others and Lips > others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0005.nii', title='fingers > other',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0006.nii', title='foot > other',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);\n",
    "plot_stat_map('/output/datasink_handson/1stLevel/sub-07/spmT_0007.nii', title='lip > other',\n",
    "    bg_img=anatimg, threshold=3, display_mode='y', cut_coords=(-5, 0, 5, 10, 15), dim=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can plot the normalized results over a template brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glass_brain('/output/datasink_handson/normalized/sub-07/wspmT_0005.nii',\n",
    "                 colorbar=True, display_mode='lyrz', black_bg=True, threshold=3,\n",
    "                 title='fingers>other');\n",
    "plot_glass_brain('/output/datasink_handson/normalized/sub-07/wspmT_0006.nii',\n",
    "                 colorbar=True, display_mode='lyrz', black_bg=True, threshold=3,\n",
    "                 title='foot>other');\n",
    "plot_glass_brain('/output/datasink_handson/normalized/sub-07/wspmT_0007.nii',\n",
    "                 colorbar=True, display_mode='lyrz', black_bg=True, threshold=3,\n",
    "                 title='lip>other');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
